{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import normalize\n",
    "import torch\n",
    "from models.model_linear import Linearnet\n",
    "from models.model_mlp import Mlp\n",
    "from models.model_cnn import Cnn\n",
    "from models.model_resnet import Resnet\n",
    "from utils.utils_data import generate_real_dataloader\n",
    "from utils.utils_data import prepare_cv_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "dset = 'cifar10'\n",
    "B = 100\n",
    "\n",
    "if dset in ['mnist', 'kmnist', 'fashion', 'cifar10']:\n",
    "    (full_train_loader, train_loader, test_loader, ordinary_train_dataset, test_dataset, K) = prepare_cv_datasets(dataname=dset, batch_size=B)\n",
    "\n",
    "for i, (data, labels) in enumerate(full_train_loader):\n",
    "    K = torch.max(\n",
    "        labels\n",
    "    ) + 1  # K is number of classes, full_train_loader is full batch\n",
    "    N,c,row,col = data.shape\n",
    "\n",
    "flattened_data = data.reshape((N, c*row*col))\n",
    "flattened_data_plus_label = torch.cat((flattened_data.reshape((c*row*col, N)), labels.unsqueeze(0))).reshape(N, c*row*col+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes:  10\n",
      "Number of clusters:  10\n",
      "(50000, 3072)\n",
      "[6 3 0 ... 1 3 1]\n",
      "[1 6 6 ... 3 0 1]\n",
      "[[1.   0.11 0.11 0.1  0.11 0.12 0.13 0.11 0.09 0.11]\n",
      " [0.1  1.   0.12 0.11 0.12 0.13 0.13 0.11 0.08 0.1 ]\n",
      " [0.1  0.12 1.   0.1  0.11 0.13 0.12 0.11 0.09 0.11]\n",
      " [0.1  0.12 0.11 1.   0.12 0.12 0.11 0.11 0.09 0.12]\n",
      " [0.1  0.12 0.11 0.1  1.   0.12 0.12 0.12 0.09 0.12]\n",
      " [0.1  0.12 0.12 0.1  0.12 1.   0.12 0.11 0.09 0.12]\n",
      " [0.12 0.12 0.12 0.1  0.11 0.12 1.   0.11 0.1  0.12]\n",
      " [0.11 0.12 0.12 0.1  0.12 0.12 0.12 1.   0.09 0.11]\n",
      " [0.1  0.1  0.11 0.11 0.11 0.12 0.13 0.11 1.   0.11]\n",
      " [0.1  0.1  0.12 0.11 0.12 0.13 0.13 0.11 0.09 1.  ]]\n",
      "Ambiguity degree:  0.13492047614284286\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of classes: \", K.item())\n",
    "num_clusters = 1*K.item()\n",
    "print(\"Number of clusters: \", num_clusters)\n",
    "X = flattened_data.numpy()\n",
    "print(X.shape)\n",
    "kmeans = KMeans(n_clusters=num_clusters, random_state=0, n_init=1).fit(X)\n",
    "print(kmeans.labels_)\n",
    "print(labels.numpy())\n",
    "\n",
    "# confusion_labels = {}\n",
    "# confusion_labels.update([(cluster,set()) for cluster in range(num_clusters)])\n",
    "# for i,cluster in enumerate(kmeans.labels_):\n",
    "#     true_label_i = labels[i].item()\n",
    "#     confusion_labels[cluster].add(true_label_i)\n",
    "\n",
    "# for cluster in confusion_labels.keys():\n",
    "#     print(f\"Cluster {cluster} Candidate Labels {confusion_labels[cluster]}\")\n",
    "\n",
    "sample_size = int(N*0.01) # 1% \n",
    "sample = random.sample(list(range(N)), sample_size)\t\n",
    "confusion_labels = np.eye(K)\n",
    "for i,cluster_i in enumerate(kmeans.labels_[sample]):\n",
    "    for j,cluster_j in enumerate(kmeans.labels_):\n",
    "        if cluster_i==cluster_j:\n",
    "            true_label_i = labels[i].item()\n",
    "            true_label_j = labels[j].item()\n",
    "            if true_label_i!=true_label_j:\n",
    "                confusion_labels[true_label_i, true_label_j] += 1\n",
    "                confusion_labels[true_label_j, true_label_i] += 1\n",
    "\n",
    "# normalize to get probs\n",
    "confusion_labels = normalize(confusion_labels, axis=1, norm='l1')\n",
    "np.fill_diagonal(confusion_labels, 1.0)\n",
    "print(np.around(confusion_labels, 2))\n",
    "print(\"Ambiguity degree: \", confusion_labels[confusion_labels<1.0].max())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('neuro')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "45a9a558b30b86d9f732c54dbfd32f3dc135cf8debc1699b6136107345de1818"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
